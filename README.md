# hass-vicuna-conversation
Conversation support for home assistant using vicuna or llama local llm

Uses similar to openAI APIs:
https://github.com/ggerganov/llama.cpp
https://github.com/keldenl/gpt-llama.cpp
https://huggingface.co/eachadea/ggml-vicuna-13b-1.1
https://www.home-assistant.io/integrations/openai_conversation/
https://github.com/home-assistant/core/tree/dev/homeassistant/components/openai_conversation

TBD improve speed using GPU:
https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g
https://github.com/qwopqwop200/GPTQ-for-LLaMa
https://rentry.org/llama-tard-v2
