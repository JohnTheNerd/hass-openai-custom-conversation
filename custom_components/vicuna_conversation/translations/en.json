{
  "config": {
    "error": {
      "cannot_connect": "Failed to connect",
      "invalid_api_key": "Invalid API key",
      "unknown": "Unexpected error, see error logs"
    },
    "step": {
      "user": {
        "data": {
          "api_key": "API key",
          "base_url": "URL"
        },
        "data_description": {
          "api_key": "API key for the LLM service.",
          "base_url": "Base URL for the LLM service."
        }
      },
      "model": {
        "data": {
          "chat_model": "Model"
        },
        "data_description": {
          "chat_model": "Select the model to use."
        }
      }
    }
  },
  "options": {
    "step": {
      "init": {
        "data": {
          "prompt": "Instructions",
          "chat_model": "Model",
          "max_tokens": "Maximum tokens to return in response",
          "temperature": "Temperature",
          "top_p": "Top P",
          "llm_hass_api": "Control Home Assistant",
          "recommended": "Recommended model settings"
        },
        "data_description": {
          "prompt": "Instruct how the LLM should respond. This can be a template.",
          "chat_model": "Select the model to use.",
          "max_tokens": "Select the maximum number of tokens to return.",
          "temperature": "Select the temperature for response variability.",
          "top_p": "Select the top P value for response diversity.",
          "llm_hass_api": "Select the level of control over Home Assistant.",
          "recommended": "Select whether to use recommended model settings."
        }
      }
    }
  }
}
